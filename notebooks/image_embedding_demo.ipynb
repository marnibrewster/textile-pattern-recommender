{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2ccHt_yzJ0n",
        "outputId": "c704af2e-ac0d-41e6-f9e1-079c5869de02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch torchvision ftfy regex tqdm\n",
        "!pip install -q git+https://github.com/openai/CLIP.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2IkOwQUS8GBn",
        "outputId": "26fc2ddc-debd-4921-e47e-ba02d53c81c9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f565c015-0e78-4093-8e9b-301e3154edf3\", \"cooper_hewitt_embeddings_sample.json\", 47702)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import clip\n",
        "import csv\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# cooper_hewitt_formatted_data.json and met_formatted_data.json were added to the content/ directory in colab before running this\n",
        "# This script was run twice, once for the cooper hewitt formatted data, and once for the met formatted data\n",
        "# To run with cooper hewitt data, uncomment Cooper block and comment out Met block\n",
        "# To run with met data, umcomment Met block and comment out Cooper block\n",
        "\n",
        "# Cooper block\n",
        "with open(\"cooper_hewitt_formatted_data.json\") as f:\n",
        "  data = json.load(f)\n",
        "# End cooper block\n",
        "\n",
        "# Met block\n",
        "# with open(\"met_formatted_data.json\") as f:\n",
        "  # data = json.load(f)\n",
        "# End met block\n",
        "\n",
        "batch_size = 50\n",
        "total = len(data)\n",
        "\n",
        "failed_log_path = Path(\"failed_images.csv\")\n",
        "log_file = failed_log_path.open(\"a\", newline=\"\")\n",
        "csv_writer = csv.writer(log_file)\n",
        "csv_writer.writerow([\"id\", \"image_url\", \"error_message\"])\n",
        "\n",
        "for start_index in range(0, total, batch_size):\n",
        "  end_index = min(start_index + batch_size, total)\n",
        "  batch = data[start_index:end_index]\n",
        "  results = []\n",
        "\n",
        "  for obj in tqdm(batch, desc=f\"Embedding batch {start_index}-{end_index}\"):\n",
        "    try:\n",
        "      url = obj.get(\"image_url\")\n",
        "      response = requests.get(url, timeout=10)\n",
        "      image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "      image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        image_features = model.encode_image(image_input)\n",
        "      \n",
        "      embedding_vector = image_features[0].cpu().tolist()\n",
        "      results.append({\n",
        "        \"id\": obj[\"id\"],\n",
        "        \"image_url\": url,\n",
        "        \"embedding\": embedding_vector,\n",
        "        \"text_fields\": obj.get(\"embedding_text\", \"\"),\n",
        "        \"metadata\": {\n",
        "            \"title\": obj[\"raw\"].get(\"title\", \"\"),\n",
        "            \"medium\": obj[\"raw\"].get(\"medium\", \"\"),\n",
        "            \"date\": obj[\"raw\"].get(\"date\", \"\"),\n",
        "            \"description\": obj[\"raw\"].get(\"description\", \"\"),\n",
        "            \"object_url\": obj.get(\"url\", \"\")\n",
        "        }\n",
        "      })\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing ID {obj.get('id')}: {e}\")\n",
        "      csv_writer.writerow([obj.get(\"id\"), obj.get(\"image_url\"), str(e)])\n",
        "      continue\n",
        "\n",
        "  batch_num = start_index // batch_size\n",
        "  # Cooper block\n",
        "  filename = f\"cooper_hewitt_embeddings_batch_{batch_num}.json\"\n",
        "  # End cooper block\n",
        "\n",
        "  # Met block\n",
        "  # filename = f\"met_embeddings_batch_{batch_num}.json\"\n",
        "  # End met block \n",
        "\n",
        "  with open(filename, \"w\") as f:\n",
        "    json.dump(results, f)\n",
        "\n",
        "log_file.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
